#  Blog

# [Joyce Rustenburg](https://twitter.com/rustenburg_J)
[link to Brock University](https://brocku.ca/humanities/humanities-research/humanities-research/humanities-research-institute)

## Assignment 2

I refer to the article ["Why are the Digital Humanities so White?"](http://dhdebates.gc.cuny.edu/debates/text/29) by Tara McPherson who discusses a parallel between hard sciences and ditial humanities using Unix and race looking through a lenticular lens which can show one image, or the other, but not both images at the same time or a merged version, e.g., a postcard of two 3-D images. 

Both the computer and the lenticular lens mediate images and objects, changing their relationship but frequently suppressing that process of relation, much like the divided departments of the contemporary university. The fragmentary knowledges encouraged by many forms and experiences of the digital neatly parallel the logics that underwrite the covert racism endemic to our times, operating in potential feedback loops, supporting each other. If scholars of race have highlighted how certain tendencies within poststructuralist theory simultaneously respond to and marginalize race, this maneuver is at least partially possible because of a parallel and increasing dispersion of electronic forms across culture, forms that simultaneously enact and shape their new modes of thinking (13).

### Article Analysis
+
   1960s  |       Unix   |        Race
 -------- | ------------ | -----------------------------
          |      modular | Content from cell 2
Content   | first column | Content in the second column
+



### Text Analysis

As Thomas Rommel writes, The history of literary computing, however, shows that only a limited number of textual phenomena can be analyzed profitably in the context of quantitative and qualitative computer-based analyses of style. These phenomena have to be linked to some surface features that can be identified by electronic means, usually by some form of pattern matching. Computers are exceptionally well suited for this kind of analysis, and only human intuition and insight, in combination with the raw computing power of machines programmed to act as highly specialized electronic tools, can make some texts or textual problems accessible to scholars.

Cite as: A Companion to Digital Humanities, ed. Susan Schreibman, Ray Siemens, John Unsworth. Oxford: Blackwell, 2004. 
http://www.digitalhumanities.org/companion/

An example:
This text analysis visualization, presents evidence that supports my core argument. 
The text analysis tool I used was [Voyant](https://voyant-tools.org). Here is the text analysis document window after I pasted in the text from the article, 
![](images/Voyant-tools-corpus.jpg). The results of the text analysis: This corpus has 1 document with 10,231 total words and 2,581 unique word forms. Created now.
Most frequent words in the corpus: unix (74); digital (62); race (52); modularity (40); new (37).
A closer look at the text as image. The size of the text is in direct proportion to the number of times the word is found in the corpus.
![](images/words-voyant-tools.jpg)



Link to [blog](https://rustenburgj.github.io/IASC-2P02/blog).




Works Cited



McPherson, Tara. 2012 Print Edition. “Why Are the Digital Humanities So White? or Thinking the Histories of Race and Computation”  http://dhdebates.gc.cuny.edu/debates/text/29 accessed March 3, 2017.




Reference
[digital humanities companion](http://www.digitalhumanities.org/companion/)
